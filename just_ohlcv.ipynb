{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmZrje3ej6QHtAJmRIzInY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dbrnjd/crypto-trading-dissertation/blob/main/just_ohlcv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07t-41HoHsyC",
        "outputId": "9a3ca88b-6f74-4c1b-b452-fbe551585878"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import collections\n",
        "\n",
        "# --- 1. Project Setup & Configuration (Phase 1) ---\n",
        "POPULATION_SIZE = 100\n",
        "NUM_GENERATIONS = 30\n",
        "MAX_TREE_DEPTH = 5\n",
        "TOURNAMENT_SIZE = 5\n",
        "ELITISM_COUNT = 2\n",
        "MUTATION_RATE = 0.1\n",
        "CROSSOVER_RATE = 0.8\n",
        "TRANSACTION_COST = 0.0005  # 0.05% per transaction\n",
        "\n",
        "# --- Data Configuration ---\n",
        "# Update this path to where your BTC/USD daily data CSV is stored.\n",
        "# The CSV must have 'Open', 'High', 'Low', 'Close', and 'Volume' columns.\n",
        "DATA_FILE_PATH = \"/content/drive/MyDrive/crypto_data/btc_daily.csv\"\n",
        "TRAINING_SPLIT = 0.8  # 80% for training, 20% for out-of-sample testing\n",
        "WINDOW_LENGTH = 250  # 250 trading days for each rolling window\n",
        "\n",
        "# --- Random Seed for Reproducibility ---\n",
        "RANDOM_SEED = 42\n",
        "random.seed(RANDOM_SEED)\n",
        "\n",
        "# --- 2. Genome Representation (Genetic Programming) ---\n",
        "\n",
        "class Node:\n",
        "    \"\"\"Represents a node in the expression tree.\"\"\"\n",
        "    def __init__(self, value, children=None):\n",
        "        self.value = value\n",
        "        self.children = children if children is not None else []\n",
        "        self.is_terminal = len(self.children) == 0\n",
        "\n",
        "    def __repr__(self):\n",
        "        \"\"\"String representation for debugging.\"\"\"\n",
        "        if self.is_terminal:\n",
        "            return str(self.value)\n",
        "        else:\n",
        "            return f\"({self.value} {' '.join(str(c) for c in self.children)})\"\n",
        "\n",
        "    def deep_copy(self):\n",
        "        \"\"\"\n",
        "        Creates a deep copy of the node and its entire subtree.\n",
        "        This is crucial for preventing infinite recursion during crossover.\n",
        "        \"\"\"\n",
        "        new_children = [child.deep_copy() for child in self.children]\n",
        "        return Node(self.value, new_children)\n",
        "\n",
        "def create_random_tree(max_depth, current_depth=0, return_type='arithmetic'):\n",
        "    \"\"\"Generates a random expression tree with a specified return type.\"\"\"\n",
        "    # Define the grammar of our genetic program\n",
        "    ARITHMETIC_SET = ['+', '-', '*', '/']\n",
        "    LOGICAL_SET = ['>', '<']\n",
        "    BOOLEAN_SET = ['AND', 'OR']\n",
        "    ALL_FUNCTIONS = ARITHMETIC_SET + LOGICAL_SET + BOOLEAN_SET + ['if']\n",
        "    TERMINAL_SET_OHLCV = ['Close', 'Open', 'High', 'Low', 'Volume']\n",
        "    TERMINAL_SET_CONSTANTS = [round(random.uniform(-1, 2), 2) for _ in range(5)]\n",
        "    LAG_RANGE = range(1, 10)\n",
        "\n",
        "    # To maintain depth constraint and ensure a mix of functions/terminals\n",
        "    if current_depth >= max_depth or (random.random() > 0.5 and return_type != 'logical'):\n",
        "        # Create a terminal node\n",
        "        term_type = random.choice(['OHLCV', 'Constant'])\n",
        "        if term_type == 'OHLCV':\n",
        "            ohlcv_value = random.choice(TERMINAL_SET_OHLCV)\n",
        "            lag_node = Node(random.choice(LAG_RANGE))\n",
        "            return Node(ohlcv_value, children=[lag_node])\n",
        "        else:\n",
        "            return Node(random.choice(TERMINAL_SET_CONSTANTS))\n",
        "    else:\n",
        "        # Create a function node\n",
        "        if return_type == 'logical':\n",
        "            # A logical tree must have a logical or boolean operator at the root\n",
        "            function = random.choice(LOGICAL_SET + BOOLEAN_SET)\n",
        "        else:\n",
        "            # An arithmetic tree can have an arithmetic or 'if' operator\n",
        "            function = random.choice(ARITHMETIC_SET + ['if'])\n",
        "\n",
        "        children = []\n",
        "        if function == 'if':\n",
        "            # The 'if' node has a condition (logical), then-clause (arithmetic), and else-clause (arithmetic)\n",
        "            children.append(create_random_tree(max_depth, current_depth + 1, return_type='logical'))\n",
        "            children.append(create_random_tree(max_depth, current_depth + 1))\n",
        "            children.append(create_random_tree(max_depth, current_depth + 1))\n",
        "        elif function in LOGICAL_SET:\n",
        "            # Relational operators have two arithmetic children\n",
        "            children.append(create_random_tree(max_depth, current_depth + 1))\n",
        "            children.append(create_random_tree(max_depth, current_depth + 1))\n",
        "        elif function in BOOLEAN_SET:\n",
        "            # Boolean operators have two logical children\n",
        "            children.append(create_random_tree(max_depth, current_depth + 1, return_type='logical'))\n",
        "            children.append(create_random_tree(max_depth, current_depth + 1, return_type='logical'))\n",
        "        else:\n",
        "            # Arithmetic operators have two arithmetic children\n",
        "            children.append(create_random_tree(max_depth, current_depth + 1))\n",
        "            children.append(create_random_tree(max_depth, current_depth + 1))\n",
        "\n",
        "        return Node(function, children)\n",
        "\n",
        "def safe_divide(numerator, denominator):\n",
        "    \"\"\"Handles division by zero by returning 1.0 if denominator is 0.\"\"\"\n",
        "    return numerator / denominator if denominator != 0 else 1.0\n",
        "\n",
        "def evaluate_tree(node, ohlcv, t):\n",
        "    \"\"\"\n",
        "    Recursively evaluates the expression tree at a given timestep.\n",
        "    Includes a failsafe to ensure a float is always returned.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if node.is_terminal:\n",
        "            if isinstance(node.value, (int, float)):\n",
        "                return float(node.value)\n",
        "            elif node.value in ['Close', 'Open', 'High', 'Low', 'Volume']:\n",
        "                lag = node.children[0].value\n",
        "                if t - lag >= 0:\n",
        "                    return float(ohlcv[node.value][t - lag])\n",
        "                else:\n",
        "                    return 0.0\n",
        "            # Failsafe for unexpected terminal values\n",
        "            else:\n",
        "                return 0.0\n",
        "        else:\n",
        "            op = node.value\n",
        "            children = node.children\n",
        "\n",
        "            if op == '+':\n",
        "                return evaluate_tree(children[0], ohlcv, t) + evaluate_tree(children[1], ohlcv, t)\n",
        "            elif op == '-':\n",
        "                return evaluate_tree(children[0], ohlcv, t) - evaluate_tree(children[1], ohlcv, t)\n",
        "            elif op == '*':\n",
        "                return evaluate_tree(children[0], ohlcv, t) * evaluate_tree(children[1], ohlcv, t)\n",
        "            elif op == '/':\n",
        "                return safe_divide(evaluate_tree(children[0], ohlcv, t), evaluate_tree(children[1], ohlcv, t))\n",
        "            elif op == '>':\n",
        "                return 1.0 if evaluate_tree(children[0], ohlcv, t) > evaluate_tree(children[1], ohlcv, t) else 0.0\n",
        "            elif op == '<':\n",
        "                return 1.0 if evaluate_tree(children[0], ohlcv, t) < evaluate_tree(children[1], ohlcv, t) else 0.0\n",
        "            elif op == 'AND':\n",
        "                return 1.0 if evaluate_tree(children[0], ohlcv, t) and evaluate_tree(children[1], ohlcv, t) else 0.0\n",
        "            elif op == 'OR':\n",
        "                return 1.0 if evaluate_tree(children[0], ohlcv, t) or evaluate_tree(children[1], ohlcv, t) else 0.0\n",
        "            elif op == 'if':\n",
        "                condition = evaluate_tree(children[0], ohlcv, t)\n",
        "                if condition:\n",
        "                    return evaluate_tree(children[1], ohlcv, t)\n",
        "                else:\n",
        "                    return evaluate_tree(children[2], ohlcv, t)\n",
        "            else:\n",
        "                return 0.0\n",
        "    except (IndexError, TypeError, ValueError):\n",
        "        # A failsafe to catch any evaluation errors and return a neutral value\n",
        "        return 0.0\n",
        "\n",
        "def tree_to_string(node):\n",
        "    \"\"\"Converts the tree to a human-readable trading rule string.\"\"\"\n",
        "    if node.is_terminal:\n",
        "        if isinstance(node.value, str) and node.children:\n",
        "            return f\"{node.value}[t-{node.children[0].value}]\"\n",
        "        else:\n",
        "            return str(node.value)\n",
        "    else:\n",
        "        op = node.value\n",
        "        if op == 'if':\n",
        "            cond = tree_to_string(node.children[0])\n",
        "            expr1 = tree_to_string(node.children[1])\n",
        "            expr2 = tree_to_string(node.children[2])\n",
        "            return f\"if ({cond}) then ({expr1}) else ({expr2})\"\n",
        "        elif op in ['AND', 'OR', '>', '<']:\n",
        "            left = tree_to_string(node.children[0])\n",
        "            right = tree_to_string(node.children[1])\n",
        "            return f\"({left} {op} {right})\"\n",
        "        else:\n",
        "            # Arithmetic operators\n",
        "            left = tree_to_string(node.children[0])\n",
        "            right = tree_to_string(node.children[1])\n",
        "            return f\"({left} {op} {right})\"\n",
        "\n",
        "# --- 3. Genetic Operators (Crossover & Mutation) ---\n",
        "\n",
        "def get_random_node(root):\n",
        "    \"\"\"Helper to select a random node from the tree.\"\"\"\n",
        "    nodes = []\n",
        "    def traverse(node):\n",
        "        nodes.append(node)\n",
        "        for child in node.children:\n",
        "            traverse(child)\n",
        "    traverse(root)\n",
        "    return random.choice(nodes)\n",
        "\n",
        "def crossover(parent1, parent2):\n",
        "    \"\"\"Performs crossover by swapping sub-trees.\"\"\"\n",
        "    # Create a deep copy of the parent to prevent modifying it in place\n",
        "    child = parent1.deep_copy()\n",
        "    crossover_point_p2 = get_random_node(parent2)\n",
        "\n",
        "    # Find a random node in the child to replace\n",
        "    crossover_point_child = get_random_node(child)\n",
        "\n",
        "    # Replace the subtree\n",
        "    crossover_point_child.value = crossover_point_p2.value\n",
        "    crossover_point_child.children = crossover_point_p2.children[:]\n",
        "\n",
        "    return child\n",
        "\n",
        "def mutate(individual):\n",
        "    \"\"\"Mutates a random node in the tree.\"\"\"\n",
        "    # Create a deep copy of the individual to prevent modifying it in place\n",
        "    mutated_individual = individual.deep_copy()\n",
        "    mutation_point = get_random_node(mutated_individual)\n",
        "\n",
        "    # Create a new sub-tree to replace the mutation point\n",
        "    new_sub_tree = create_random_tree(MAX_TREE_DEPTH)\n",
        "\n",
        "    mutation_point.value = new_sub_tree.value\n",
        "    mutation_point.children = new_sub_tree.children[:]\n",
        "\n",
        "    return mutated_individual\n",
        "\n",
        "# --- 4. Fitness Function & Backtesting ---\n",
        "\n",
        "def compute_sharpe_ratio(returns):\n",
        "    \"\"\"Calculates the annualised Sharpe Ratio.\"\"\"\n",
        "    if len(returns) < 2:\n",
        "        return 0\n",
        "    daily_returns = np.array(returns)\n",
        "    if np.std(daily_returns) == 0:\n",
        "        return 0\n",
        "    # Annualised return and standard deviation\n",
        "    annualised_return = np.mean(daily_returns) * np.sqrt(252)\n",
        "    annualised_std_dev = np.std(daily_returns) * np.sqrt(252)\n",
        "    return annualised_return / annualised_std_dev\n",
        "\n",
        "def backtest(strategy, ohlcv):\n",
        "    \"\"\"\n",
        "    Backtests a single strategy on the provided OHLCV data.\n",
        "    The strategy produces a trading signal (+1, -1, 0)\n",
        "    which is then converted to a position and returns.\n",
        "    \"\"\"\n",
        "    position = 0  # 1 for long, -1 for short, 0 for cash\n",
        "    daily_returns = []\n",
        "    max_lag = 10  # A safe max lag based on current terminal set\n",
        "    if len(ohlcv['Close']) <= max_lag:\n",
        "        return []\n",
        "\n",
        "    for t in range(max_lag, len(ohlcv['Close'])):\n",
        "        # Calculate daily change for return calculation\n",
        "        price_change = ohlcv['Close'][t] - ohlcv['Close'][t-1]\n",
        "\n",
        "        # Calculate returns based on previous day's position\n",
        "        daily_return = position * price_change / ohlcv['Close'][t-1]\n",
        "\n",
        "        # Evaluate the strategy to get the new signal\n",
        "        signal_raw = evaluate_tree(strategy, ohlcv, t)\n",
        "\n",
        "        # Convert raw signal to a simplified trading signal\n",
        "        new_position = 0\n",
        "        if signal_raw > 0:\n",
        "            new_position = 1\n",
        "        elif signal_raw < 0:\n",
        "            new_position = -1\n",
        "\n",
        "        # Apply transaction cost only if position changes\n",
        "        if abs(new_position - position) > 0:\n",
        "            daily_return -= TRANSACTION_COST * abs(new_position - position)\n",
        "\n",
        "        daily_returns.append(daily_return)\n",
        "        position = new_position\n",
        "\n",
        "    return daily_returns\n",
        "\n",
        "def evaluate_agent(agent, full_ohlcv_data, window_length):\n",
        "    \"\"\"Evaluates an agent on multiple rolling windows.\"\"\"\n",
        "    all_returns = []\n",
        "    for i in range(len(full_ohlcv_data) - window_length):\n",
        "        window_data = full_ohlcv_data.iloc[i:i + window_length]\n",
        "\n",
        "        # Convert DataFrame window to dict for tree evaluation\n",
        "        window_ohlcv_dict = {\n",
        "            'Open': window_data['Open'].tolist(),\n",
        "            'High': window_data['High'].tolist(),\n",
        "            'Low': window_data['Low'].tolist(),\n",
        "            'Close': window_data['Close'].tolist(),\n",
        "            'Volume': window_data['Volume'].tolist()\n",
        "        }\n",
        "\n",
        "        returns = backtest(agent, window_ohlcv_dict)\n",
        "        all_returns.extend(returns)\n",
        "\n",
        "    return compute_sharpe_ratio(all_returns)\n",
        "\n",
        "\n",
        "# --- The Main Evolutionary Loop ---\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to run the genetic algorithm.\"\"\"\n",
        "\n",
        "    # Load and split data\n",
        "    try:\n",
        "        df = pd.read_csv(DATA_FILE_PATH, parse_dates=['Date']).sort_values('Date')\n",
        "        df.set_index('Date', inplace=True)\n",
        "        # Rename the 'Volume BTC' column to 'Volume' to be used in the algorithm\n",
        "        if 'Volume BTC' in df.columns:\n",
        "            df.rename(columns={'Volume BTC': 'Volume'}, inplace=True)\n",
        "        # Ensure the 'Volume' column exists for the algorithm\n",
        "        if 'Volume' not in df.columns:\n",
        "            print(\"Error: The CSV file does not contain a 'Volume' or 'Volume BTC' column.\")\n",
        "            return\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file {DATA_FILE_PATH} was not found. Please update the path.\")\n",
        "        return\n",
        "\n",
        "    # Split into training and out-of-sample sets\n",
        "    train_size = int(len(df) * TRAINING_SPLIT)\n",
        "    train_data = df.iloc[:train_size]\n",
        "    test_data = df.iloc[train_size:]\n",
        "\n",
        "    print(f\"Training data size: {len(train_data)} days\")\n",
        "    print(f\"Out-of-sample data size: {len(test_data)} days\")\n",
        "\n",
        "    # Initialize population with random trees\n",
        "    population = [create_random_tree(MAX_TREE_DEPTH) for _ in range(POPULATION_SIZE)]\n",
        "\n",
        "    for generation in range(NUM_GENERATIONS):\n",
        "        print(f\"--- Generation {generation+1}/{NUM_GENERATIONS} ---\")\n",
        "\n",
        "        # Evaluate fitness for each individual on rolling windows\n",
        "        fitness_scores = [evaluate_agent(ind, train_data, WINDOW_LENGTH) for ind in population]\n",
        "\n",
        "        # Find the best individual and its score\n",
        "        best_individual_index = np.argmax(fitness_scores)\n",
        "        best_individual = population[best_individual_index]\n",
        "        best_score = fitness_scores[best_individual_index]\n",
        "\n",
        "        avg_score = np.mean(fitness_scores)\n",
        "\n",
        "        print(f\"Average Fitness: {avg_score:.4f}\")\n",
        "        print(f\"Best Fitness: {best_score:.4f}\")\n",
        "\n",
        "        # Selection (Tournament Selection with Elitism)\n",
        "        new_population = []\n",
        "\n",
        "        # Elitism: carry over the top performers\n",
        "        elite_indices = np.argsort(fitness_scores)[-ELITISM_COUNT:]\n",
        "        for idx in elite_indices:\n",
        "            new_population.append(population[idx])\n",
        "\n",
        "        # Fill the rest of the population\n",
        "        while len(new_population) < POPULATION_SIZE:\n",
        "            tournament_candidates = random.sample(list(zip(population, fitness_scores)), TOURNAMENT_SIZE)\n",
        "            winner = max(tournament_candidates, key=lambda x: x[1])[0]\n",
        "            new_population.append(winner)\n",
        "\n",
        "        # Crossover\n",
        "        offspring_population = []\n",
        "        for i in range(0, POPULATION_SIZE, 2):\n",
        "            p1 = new_population[i]\n",
        "            p2 = new_population[i+1] if i + 1 < POPULATION_SIZE else None\n",
        "\n",
        "            if p2 is not None and random.random() < CROSSOVER_RATE:\n",
        "                child1 = crossover(p1, p2)\n",
        "                child2 = crossover(p2, p1)\n",
        "                offspring_population.extend([child1, child2])\n",
        "            else:\n",
        "                offspring_population.append(p1)\n",
        "                if p2 is not None:\n",
        "                    offspring_population.append(p2)\n",
        "\n",
        "        # Mutation\n",
        "        for i in range(len(offspring_population)):\n",
        "            if random.random() < MUTATION_RATE:\n",
        "                offspring_population[i] = mutate(offspring_population[i])\n",
        "\n",
        "        population = offspring_population\n",
        "\n",
        "    # --- Final Outputs ---\n",
        "\n",
        "    final_fitness = [evaluate_agent(ind, train_data, WINDOW_LENGTH) for ind in population]\n",
        "    final_best_index = np.argmax(final_fitness)\n",
        "    final_best_strategy = population[final_best_index]\n",
        "    final_best_rule_string = tree_to_string(final_best_strategy)\n",
        "\n",
        "    # In-sample (IS) performance on the full training set\n",
        "    is_returns = backtest(final_best_strategy, {col: train_data[col].tolist() for col in train_data.columns})\n",
        "    is_sharpe = compute_sharpe_ratio(is_returns)\n",
        "\n",
        "    # Out-of-sample (OOS) performance on the held-out test set\n",
        "    oos_returns = backtest(final_best_strategy, {col: test_data[col].tolist() for col in test_data.columns})\n",
        "    oos_sharpe = compute_sharpe_ratio(oos_returns)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"           Final Experiment Results            \")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"In-Sample Sharpe Ratio: {is_sharpe:.4f}\")\n",
        "    print(f\"Out-of-sample Sharpe Ratio: {oos_sharpe:.4f}\")\n",
        "    print(\"\\n--- Final Best Strategy Rule ---\")\n",
        "    print(final_best_rule_string)\n",
        "    print(\"=\"*50)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrXEWj21H7Sc",
        "outputId": "451d4bc6-3cde-4747-ef1a-609c943f9fd1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data size: 3127 days\n",
            "Out-of-sample data size: 782 days\n",
            "--- Generation 1/30 ---\n",
            "Average Fitness: 0.0030\n",
            "Best Fitness: 0.0597\n",
            "--- Generation 2/30 ---\n",
            "Average Fitness: 0.0400\n",
            "Best Fitness: 0.0597\n",
            "--- Generation 3/30 ---\n",
            "Average Fitness: 0.0448\n",
            "Best Fitness: 0.0606\n",
            "--- Generation 4/30 ---\n",
            "Average Fitness: 0.0394\n",
            "Best Fitness: 0.0606\n",
            "--- Generation 5/30 ---\n",
            "Average Fitness: 0.0465\n",
            "Best Fitness: 0.0601\n",
            "--- Generation 6/30 ---\n",
            "Average Fitness: 0.0430\n",
            "Best Fitness: 0.0601\n",
            "--- Generation 7/30 ---\n",
            "Average Fitness: 0.0346\n",
            "Best Fitness: 0.0601\n",
            "--- Generation 8/30 ---\n",
            "Average Fitness: 0.0310\n",
            "Best Fitness: 0.0601\n",
            "--- Generation 9/30 ---\n",
            "Average Fitness: 0.0340\n",
            "Best Fitness: 0.0601\n",
            "--- Generation 10/30 ---\n",
            "Average Fitness: 0.0418\n",
            "Best Fitness: 0.0601\n",
            "--- Generation 11/30 ---\n",
            "Average Fitness: 0.0364\n",
            "Best Fitness: 0.0601\n",
            "--- Generation 12/30 ---\n",
            "Average Fitness: 0.0322\n",
            "Best Fitness: 0.0602\n",
            "--- Generation 13/30 ---\n",
            "Average Fitness: 0.0352\n",
            "Best Fitness: 0.0602\n",
            "--- Generation 14/30 ---\n",
            "Average Fitness: 0.0304\n",
            "Best Fitness: 0.0602\n",
            "--- Generation 15/30 ---\n",
            "Average Fitness: 0.0400\n",
            "Best Fitness: 0.0601\n",
            "--- Generation 16/30 ---\n",
            "Average Fitness: 0.0447\n",
            "Best Fitness: 0.0602\n",
            "--- Generation 17/30 ---\n",
            "Average Fitness: 0.0352\n",
            "Best Fitness: 0.0601\n",
            "--- Generation 18/30 ---\n",
            "Average Fitness: 0.0471\n",
            "Best Fitness: 0.0602\n",
            "--- Generation 19/30 ---\n",
            "Average Fitness: 0.0412\n",
            "Best Fitness: 0.0602\n",
            "--- Generation 20/30 ---\n",
            "Average Fitness: 0.0478\n",
            "Best Fitness: 0.0602\n",
            "--- Generation 21/30 ---\n",
            "Average Fitness: 0.0322\n",
            "Best Fitness: 0.0602\n",
            "--- Generation 22/30 ---\n",
            "Average Fitness: 0.0370\n",
            "Best Fitness: 0.0602\n",
            "--- Generation 23/30 ---\n",
            "Average Fitness: 0.0335\n",
            "Best Fitness: 0.0602\n",
            "--- Generation 24/30 ---\n",
            "Average Fitness: 0.0275\n",
            "Best Fitness: 0.0602\n",
            "--- Generation 25/30 ---\n",
            "Average Fitness: 0.0418\n",
            "Best Fitness: 0.0602\n",
            "--- Generation 26/30 ---\n",
            "Average Fitness: 0.0483\n",
            "Best Fitness: 0.0602\n",
            "--- Generation 27/30 ---\n",
            "Average Fitness: 0.0519\n",
            "Best Fitness: 0.0602\n",
            "--- Generation 28/30 ---\n",
            "Average Fitness: 0.0459\n",
            "Best Fitness: 0.0606\n",
            "--- Generation 29/30 ---\n",
            "Average Fitness: 0.0400\n",
            "Best Fitness: 0.0602\n",
            "--- Generation 30/30 ---\n",
            "Average Fitness: 0.0352\n",
            "Best Fitness: 0.0602\n",
            "\n",
            "==================================================\n",
            "           Final Experiment Results            \n",
            "==================================================\n",
            "In-Sample Sharpe Ratio: 0.0579\n",
            "Out-of-sample Sharpe Ratio: 0.0821\n",
            "\n",
            "--- Final Best Strategy Rule ---\n",
            "Volume[t-6]\n",
            "==================================================\n"
          ]
        }
      ]
    }
  ]
}